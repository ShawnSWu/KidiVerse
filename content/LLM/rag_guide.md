# Retrievalâ€‘Augmented Generation (RAG)

**RAG** combines vector search with languageâ€‘model generation so your application can answer questions using *fresh, domainâ€‘specific knowledge* instead of the modelâ€™s static training data.

---

## 1â€‚Why RAG?

| Benefit               | Detail                                                         |
|-----------------------|----------------------------------------------------------------|
| **Upâ€‘toâ€‘date answers**| Inject current docs; bypass the modelâ€™s knowledge cutâ€‘off.     |
| **Smaller models**    | Offload facts to the retriever; keep the LLM lightweight.      |
| **Reduced hallucination** | Source grounding text that the model can quote or cite.   |
| **Data governance**   | Easily remove or update knowledge by reâ€‘indexing documents.    |

---

## 2â€‚Pipeline Anatomy

```mermaid
flowchart TD
  U[User Query] --> E[Embedder]
  E --> V[Vector<br/>DB]
  V -->|Topâ€‘k docs| C[Context]
  U --> P[Prompt Builder]
  C --> P
  P --> L[LLMðŸ”®]
  L --> R[Response]
```

1. **Embed** query and compare against a vector index.  
2. **Retrieve** topâ€‘k chunks; optional keyword or filter stage.  
3. **Compose prompt**: system msg + retrieved context + user query.  
4. **Generate** answer with citations.

---

## 3â€‚Retrieval Layer

### 3.1â€‚Embedding Models

| Model        | Dim  | Strength                 |
|--------------|------|--------------------------|
| `text-embedding-3-small` | 1â€¯536 | Costâ€‘effective, multilingual |
| `bge-large-en` | 1â€¯024 | Openâ€‘source, rerank friendly |
| `instructor-xl`| 768  | Instructionâ€‘tuned for QA |

> **Rule:** Use domainâ€‘trained or instruction embeddings if your queries are questionâ€‘like.

### 3.2â€‚Chunking Strategy

```text
Chunk size: 512â€“1â€¯024 tokens
Overlap   : 10â€“20â€¯%
Heuristic : split on headings > paragraphs > sentences
```

### 3.3â€‚Vector Databases

| DB       | Index Type      | Notes                        |
|----------|-----------------|------------------------------|
| **Qdrant**   | HNSW + payload | Rust core, dynamic filters  |
| **Pinecone** | ScaNN/HNSW     | Fullyâ€‘managed cloud         |
| **Milvus**   | IVFâ€‘Flat, GPU  | Scales to billions of vectors|

---

## 4â€‚Generation Layer

### 4.1â€‚Prompt Template (Jinja style)

```jinja
SYSTEM:
You are an expert assistant. Cite sources like [1], [2].

CONTEXT:
{% for doc in docs %}
[{{ loop.index }}] {{ doc.content | truncate(300) }}
{% endfor %}

USER: {{ question }}
ASSISTANT:
```

### 4.2â€‚Python Skeleton (LangChain)

```python
from langchain.embeddings import OpenAIEmbeddings
from langchain.vectorstores import Qdrant
from langchain.chat_models import ChatOpenAI
from langchain.chains import RetrievalQA

emb = OpenAIEmbeddings(model="text-embedding-3-small")
vectordb = Qdrant(collection_name="kb", embeddings=emb)

llm  = ChatOpenAI(model_name="gpt-4o-mini", temperature=0.2)
qa   = RetrievalQA.from_chain_type(
         llm=llm,
         chain_type="stuff",
         retriever=vectordb.as_retriever(search_kwargs={"k": 4})
       )

qa({"query": "How does PID control work?"})
```

---

## 5â€‚Evaluation & Guardrails

| Metric              | Checksâ€¦             | Tooling            |
|---------------------|---------------------|--------------------|
| **Groundedness**    | Citation accuracy   | Atlas Eval, RAGAS |
| **Answer F1 / BLEU**| Content relevancy   | LMâ€‘evalâ€‘harness    |
| **Latency & cost**  | Realâ€‘time SLA       | Prometheus + Grafana |
| **Toxicity / PII**  | Safety compliance   | OpenAI Moderation API |

---

## 6â€‚Operational Tips

1. **Hybrid Retrieval** (BM25 + vectors) boosts recall on rare terms.  
2. **Coldâ€‘cache preâ€‘warm:** preâ€‘query popular FAQs during deployment.  
3. **Index refresh cadence:** realâ€‘time via Kafka CDC or nightly batch.  
4. **Citation truncation:** store doc titles + hashes to keep prompts short.  
5. **Fallbacks:** if retrieval returns <3 docs â†’ switch to direct LLM answer with disclaimer.

---

## 7â€‚Security Considerations

- **Strip PII** before embedding; vectors are hard to delete.  
- **Tenant isolation:** namespaced collections per customer; sign requests.  
- **Prompt injection defense:** validate and sanitize retrieved text.

---

## 8â€‚RAG Checklist âœ…

- [ ] Domain corpus collected & deduplicated  
- [ ] Embeddings evaluated (`cos_sim` vs. `dot_prod`)  
- [ ] Vector DB latency <â€¯100â€¯ms at p95  
- [ ] Prompt template includes citations & role separation  
- [ ] Offline eval >â€¯85â€¯% groundedness, <â€¯1â€¯% toxicity  
- [ ] Dashboards & alerts configured

---

## 9â€‚Further Reading

- Lewis etâ€¯al., *Retrievalâ€‘Augmented Generation* (2020)  
- LlamaIndex docs â€“ <https://www.llamaindex.ai/>  
- LangChain RAG cookbook â€“ <https://python.langchain.com/docs/use_cases/question_answering/>

*Build once, reâ€‘index oftenâ€”your model will thank you.* âœ¨
